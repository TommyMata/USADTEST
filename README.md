# Call Middleware - Phone Call Transcription System

Complete system to simulate phone calls, capture audio via WebSocket and process it with AI for real-time transcription.

## ğŸ”„ How Does the System Work?

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         WebSocket          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  call_simulator.py  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚   middleware.py      â”‚
â”‚  (Client)           â”‚    Audio streaming          â”‚   (Server)           â”‚
â”‚                     â”‚    in 3200-byte chunks      â”‚                      â”‚
â”‚  - Reads sample.wav â”‚                             â”‚  - Receives chunks   â”‚
â”‚  - Sends chunks     â”‚                             â”‚  - Accumulates audio â”‚
â”‚  - Simulates call   â”‚                             â”‚  - Processes with AI â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â”‚
                                                              â–¼
                                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                    â”‚   Deepgram API       â”‚
                                                    â”‚   (Transcription)    â”‚
                                                    â”‚                      â”‚
                                                    â”‚  - Receives audio    â”‚
                                                    â”‚  - Detects language  â”‚
                                                    â”‚  - Transcribes text  â”‚
                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Flow

1. **`middleware.py`** (Server) - Starts and waits for WebSocket connections
2. **`call_simulator.py`** (Client) - Connects to server and simulates a call
3. Client reads `sample.wav` and sends it in **3200-byte chunks**
4. Server **accumulates all chunks** in a buffer
5. When call ends (WebSocket closes):
   - Server processes complete audio with **Deepgram**
   - Gets transcription, confidence and detected language
   - Displays results in console

## ğŸ“‹ Requirements

- Python 3.7+
- Deepgram account (for AI transcription)

## ğŸ”§ Installation

1. Install dependencies:
```bash
pip install deepgram-sdk python-dotenv fastapi uvicorn websockets openai
```

2. Configure Deepgram API key in `.env` file:
```env
DEEPGRAM_API_KEY=your_api_key_here
```

## ğŸš€ Usage

### Option 1: Complete Call Simulation System (RECOMMENDED)

This is the main project flow - simulates a real phone call:

**Step 1: Start the middleware server**
```bash
python middleware.py
```
You'll see:
```
ğŸš€ Middleware server started at ws://localhost:8000/stream
â³ Waiting for incoming calls...
```

**Step 2: In another terminal, run the simulator**
```bash
python call_simulator.py
```

The simulator:
- Connects to server via WebSocket
- Reads `sample.wav` and sends it in chunks (simulating live audio)
- Closes connection

The server:
- Receives all chunks
- When call ends, processes audio with Deepgram
- Displays complete transcription

**Option 2: Automated Script**
```bash
python test_call_system.py
```
This script starts both processes automatically.

## ğŸ“ Project Files

### ğŸ”¥ Main Files (Call System)

- **`middleware.py`**: WebSocket server that receives audio and processes it with Deepgram
  - Listens on `ws://localhost:8000/stream`
  - Accumulates audio chunks
  - Transcribes when call ends
  
- **`call_simulator.py`**: Client that simulates a phone call
  - Reads `sample.wav`
  - Sends audio in chunks via WebSocket
  - Simulates real-time transmission

- **`test_call_system.py`**: Automated script that runs both processes
- **`sample.wav`**: Sample audio file (204KB)

## ğŸ¯ Features

- âœ… Automatic language detection
- âœ… Smart text formatting
- âœ… Transcription confidence indicator
- âœ… WAV file support
- âœ… Robust error handling

## ğŸ”„ System Flow

### Main System (Call Simulation)
```
1. Middleware server starts and waits for connections
2. Client connects via WebSocket
3. Client sends audio in 3200-byte chunks
4. Server accumulates all chunks
5. Client closes connection (end of call)
6. Server processes complete audio with Deepgram AI
7. Server displays transcription
```

## ğŸŒ Supported Languages

Deepgram's Nova-2 model supports multiple languages including:
- Spanish (es)
- English (en)
- And many more...

Automatic language detection is enabled by default.

## ğŸ“Š Example Output

### Middleware Server (`middleware.py`)
```
ğŸš€ Middleware server started at ws://localhost:8000/stream
â³ Waiting for incoming calls...

ğŸ“ Call started - Client connected
ğŸ“¡ Chunk received: 3200 bytes (Total: 3200 bytes)
ğŸ“¡ Chunk received: 3200 bytes (Total: 6400 bytes)
...
ğŸ“¡ Chunk received: 2768 bytes (Total: 204368 bytes)
ğŸ“´ Call ended - Processing complete audio...
ğŸ¤– Sending 204368 bytes to Deepgram for transcription...

============================================================
ğŸ”Š CALL TRANSCRIPTION:
============================================================
   ğŸ“ Text: Hello. This is a robotic test for development purposes.
   âœ… Confidence: 93.16%
   ğŸŒ Language: en
============================================================
```

### Client Simulator (`call_simulator.py`)
```
ğŸ“ Starting phone call simulation...
ğŸ”Œ Connecting to middleware server...

âœ… Connected to server
ğŸ“ File: sample.wav (204368 bytes)
ğŸ“¡ Sending audio in 3200-byte chunks...

   Chunk #1: 3200 bytes sent (Total: 3200/204368)
   Chunk #2: 3200 bytes sent (Total: 6400/204368)
   ...
   Chunk #64: 2768 bytes sent (Total: 204368/204368)

âœ… Transmission completed: 64 chunks, 204368 total bytes
ğŸ“´ Closing connection...
```

âœ… Conectado al servidor
ğŸ“ Archivo: sample.wav (204368 bytes)
ğŸ“¡ Enviando audio en chunks de 3200 bytes...

   Chunk #1: 3200 bytes enviados (Total: 3200/204368)
   Chunk #2: 3200 bytes enviados (Total: 6400/204368)
   ...
   Chunk #64: 2768 bytes enviados (Total: 204368/204368)

âœ… TransmisiÃ³n completada: 64 chunks, 204368 bytes totales
ğŸ“´ Cerrando conexiÃ³n...
```

## ğŸ› ï¸ PersonalizaciÃ³n

### Modificar el tamaÃ±o de chunks
## ğŸ› ï¸ Customization

### Modify chunk size

In `call_simulator.py`, change the chunk size:
```python
while chunk := f.read(3200):  # Change 3200 to desired size
```

### Configure transcription options

In `middleware.py`, customize Deepgram options:
```python
response = deepgram.listen.v1.media.transcribe_file(
    request=audio_data,
    model="nova-2",           # AI model
    smart_format=True,        # Smart formatting
    detect_language=True,     # Automatic detection
    diarize=True,            # Separate by speakers
    punctuate=True,          # Add punctuation
    utterances=True,         # Split by phrases
)
```

## â“ Frequently Asked Questions

### Which file actually processes the audio?

**`middleware.py`** is the file that processes audio with AI.

### How does the call simulation work?

1. `call_simulator.py` acts as a **phone** making a call
2. `middleware.py` acts as a **telephony server** receiving the call
3. Audio is transmitted in **real-time** (small chunks with delays)
4. When call ends, server processes all accumulated audio

### Can I use my own audio file?

Yes, simply replace `sample.wav` with your WAV file.

### Does it work with other audio formats?

Deepgram supports: WAV, MP3, MP4, FLAC, OGG, WebM, etc. Just change the filename in the scripts.

## ğŸ“ Notes

- Audio file should be in WAV format
- Deepgram API key must have available credits
- For large files, consider using streaming instead of batch transcription
